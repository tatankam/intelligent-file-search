{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this notebook in the same virtual environment with superlinked server\n",
    "to ensure the same version of `superlinked` framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superlinked==29.1.0\n",
      "superlinked-server==1.37.0\n"
     ]
    }
   ],
   "source": [
    "!pip freeze | grep superlinked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project_dir is added to sys.path\n",
      "/home/biso/development/my_projects/intelligent-file-search\n",
      "['/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '', '/home/biso/development/my_projects/.venv/lib/python3.12/site-packages', '/home/biso/development/my_projects/intelligent-file-search']\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Determine current working directory\n",
    "cwd = Path.cwd()\n",
    "\n",
    "# Adapt logic for your specific project structure\n",
    "if cwd.name == \"intelligent-file-search\":\n",
    "    project_dir = cwd\n",
    "elif cwd.name == \"notebooks\":\n",
    "    project_dir = cwd.parent\n",
    "else:\n",
    "    # fallback (e.g., if inside a subfolder deeper in notebooks or dataset)\n",
    "    project_dir = cwd\n",
    "    while project_dir.name != \"intelligent-file-search\" and project_dir != project_dir.parent:\n",
    "        project_dir = project_dir.parent\n",
    "\n",
    "superlinked_app_dir = project_dir / \"superlinked_app\"\n",
    "assert superlinked_app_dir.exists(), (\n",
    "    f\"{superlinked_app_dir} does not exist\\n\"\n",
    "    \"Are you sure you are in or below the intelligent-file-search directory?\"\n",
    ")\n",
    "\n",
    "if str(project_dir) not in sys.path:\n",
    "    sys.path.append(str(project_dir))\n",
    "    print(\"project_dir is added to sys.path\")\n",
    "else:\n",
    "    print(\"project_dir is already in sys.path\")\n",
    "print(project_dir)\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is to use the collection_name=filesearch or file_monkesearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ[\"APP_ID\"] = \"filesearch\"\n",
    "os.environ[\"APP_ID\"] = \"file_monkesearch\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/biso/development/my_projects/intelligent-file-search/notebooks\n"
     ]
    }
   ],
   "source": [
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patch .env variables to absolute paths\n",
    "import os\n",
    "os.chdir(\"..\")  # Move up to /intelligent-file-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded categories: ['css', 'csv', 'epub+zip', 'geo+json', 'gif', 'html', 'java-archive', 'javascript', 'jpeg', 'json', 'markdown', 'mp4', 'msword', 'octet-stream', 'ogg', 'pdf', 'pgp-keys', 'pkcs12', 'plain', 'png', 'svg+xml', 'unknown', 'vnd.a', 'vnd.android.package-archive', 'vnd.exstream-package', 'vnd.groove-tool-template', 'vnd.microsoft.icon', 'vnd.ms-excel', 'vnd.oasis.opendocument.spreadsheet', 'vnd.oasis.opendocument.text', 'vnd.openxmlformats-officedocument.spreadsheetml.sheet', 'vnd.openxmlformats-officedocument.wordprocessingml.document', 'webm', 'x-diff', 'x-matroska', 'x-ms-wmv', 'x-msdos-program', 'x-object', 'x-python', 'x-sh', 'xml', 'zip']\n",
      "10:56:04 sentence_transformers.SentenceTransformer INFO   Load pretrained SentenceTransformer: sentence-transformers/paraphrase-MiniLM-L3-v2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31bdd77fbc2f4fb2ab0a1640be9c74d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:56:09 superlinked.framework.common.space.embedding.model_based.embedding_engine_manager INFO   Consider caching model dimension.\n",
      "10:56:10 superlinked.framework.common.space.embedding.model_based.embedding_engine_manager INFO   Consider caching model dimension.\n",
      "10:56:10 superlinked.framework.common.space.embedding.model_based.embedding_engine_manager INFO   Consider caching model dimension.\n",
      "10:56:10 superlinked.framework.dsl.index.index INFO   initialized index\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from superlinked import framework as sl\n",
    "\n",
    "#from superlinked_app.index import file_index, file_schema\n",
    "from superlinked_app.index import file_index, file_schema\n",
    "from superlinked_app.query import query\n",
    "from superlinked_app.api import vector_database\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:58:57 httpx INFO   HTTP Request: GET https://bad13d43-afc8-44b5-8b37-2fa1eb4f0236.eu-west-1-0.aws.cloud.qdrant.io:6333 \"HTTP/1.1 200 OK\"\n",
      "10:58:57 httpx INFO   HTTP Request: GET https://bad13d43-afc8-44b5-8b37-2fa1eb4f0236.eu-west-1-0.aws.cloud.qdrant.io:6333/collections/file_monkesearch/exists \"HTTP/1.1 200 OK\"\n",
      "10:58:57 httpx INFO   HTTP Request: GET https://bad13d43-afc8-44b5-8b37-2fa1eb4f0236.eu-west-1-0.aws.cloud.qdrant.io:6333/collections/file_monkesearch \"HTTP/1.1 200 OK\"\n",
      "10:58:57 httpx INFO   HTTP Request: PUT https://bad13d43-afc8-44b5-8b37-2fa1eb4f0236.eu-west-1-0.aws.cloud.qdrant.io:6333/collections/file_monkesearch/index?wait=true \"HTTP/1.1 200 OK\"\n",
      "10:58:57 httpx INFO   HTTP Request: PUT https://bad13d43-afc8-44b5-8b37-2fa1eb4f0236.eu-west-1-0.aws.cloud.qdrant.io:6333/collections/file_monkesearch/index?wait=true \"HTTP/1.1 200 OK\"\n",
      "10:58:57 httpx INFO   HTTP Request: PUT https://bad13d43-afc8-44b5-8b37-2fa1eb4f0236.eu-west-1-0.aws.cloud.qdrant.io:6333/collections/file_monkesearch/index?wait=true \"HTTP/1.1 200 OK\"\n",
      "10:58:58 httpx INFO   HTTP Request: PUT https://bad13d43-afc8-44b5-8b37-2fa1eb4f0236.eu-west-1-0.aws.cloud.qdrant.io:6333/collections/file_monkesearch/index?wait=true \"HTTP/1.1 200 OK\"\n",
      "10:58:58 httpx INFO   HTTP Request: PUT https://bad13d43-afc8-44b5-8b37-2fa1eb4f0236.eu-west-1-0.aws.cloud.qdrant.io:6333/collections/file_monkesearch/index?wait=true \"HTTP/1.1 200 OK\"\n",
      "10:58:58 httpx INFO   HTTP Request: PUT https://bad13d43-afc8-44b5-8b37-2fa1eb4f0236.eu-west-1-0.aws.cloud.qdrant.io:6333/collections/file_monkesearch/index?wait=true \"HTTP/1.1 200 OK\"\n",
      "10:58:58 httpx INFO   HTTP Request: PUT https://bad13d43-afc8-44b5-8b37-2fa1eb4f0236.eu-west-1-0.aws.cloud.qdrant.io:6333/collections/file_monkesearch/index?wait=true \"HTTP/1.1 200 OK\"\n",
      "10:58:58 httpx INFO   HTTP Request: PUT https://bad13d43-afc8-44b5-8b37-2fa1eb4f0236.eu-west-1-0.aws.cloud.qdrant.io:6333/collections/file_monkesearch/index?wait=true \"HTTP/1.1 200 OK\"\n",
      "10:58:58 httpx INFO   HTTP Request: PUT https://bad13d43-afc8-44b5-8b37-2fa1eb4f0236.eu-west-1-0.aws.cloud.qdrant.io:6333/collections/file_monkesearch/index?wait=true \"HTTP/1.1 200 OK\"\n",
      "10:58:58 superlinked.framework.query.query_dag_evaluator INFO   initialized query dag\n",
      "10:58:58 superlinked.framework.online.online_dag_evaluator INFO   initialized entity dag\n",
      "10:58:58 superlinked.framework.dsl.executor.interactive.interactive_executor INFO   started interactive app\n"
     ]
    }
   ],
   "source": [
    "source = sl.InteractiveSource(file_schema)\n",
    "executor = sl.InteractiveExecutor(\n",
    "    sources=[source],\n",
    "    indices=[file_index],\n",
    "    vector_database=vector_database,\n",
    ")\n",
    "app = executor.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown query parameters: natural_query.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 14\u001b[0m\n\u001b[1;32m      8\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnatural_query\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecent PDF files about fashion or sport\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlimit\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m     11\u001b[0m }\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Run the query with natural language interface\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Print the actual interpreted search parameters extracted by NLQ\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSearch Parameters Parsed by NLQ:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m<@beartype(superlinked.framework.dsl.query.query_mixin.QueryMixin.query) at 0x72cdb9412200>:34\u001b[0m, in \u001b[0;36mquery\u001b[0;34m(__beartype_object_1199700608, __beartype_get_violation, __beartype_conf, __beartype_args_name_keywordable, __beartype_object_1188762160, __beartype_check_meta, __beartype_func, *args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/development/my_projects/.venv/lib/python3.12/site-packages/superlinked/framework/dsl/query/query_mixin.py:73\u001b[0m, in \u001b[0;36mQueryMixin.query\u001b[0;34m(self, query_descriptor, **params)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mquery\u001b[39m(\u001b[38;5;28mself\u001b[39m, query_descriptor: QueryDescriptor, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m QueryResult:\n\u001b[1;32m     60\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03m    Execute a query using the provided QueryDescriptor and additional parameters.\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m        QueryException: If the query index is not found among the executor's indices.\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mAsyncUtil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masync_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_descriptor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/development/my_projects/.venv/lib/python3.12/site-packages/superlinked/framework/common/util/async_util.py:35\u001b[0m, in \u001b[0;36mAsyncUtil.run\u001b[0;34m(cls, coroutine)\u001b[0m\n\u001b[1;32m     33\u001b[0m loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_get_loop()\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loop \u001b[38;5;129;01mand\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mis_running():\n\u001b[0;32m---> 35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_async_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoroutine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_sync_context(loop, coroutine)\n",
      "File \u001b[0;32m~/development/my_projects/.venv/lib/python3.12/site-packages/superlinked/framework/common/util/async_util.py:58\u001b[0m, in \u001b[0;36mAsyncUtil._handle_async_context\u001b[0;34m(cls, loop, coroutine)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(loop, NEST_ASYNCIO_ATTR) \u001b[38;5;129;01mand\u001b[39;00m loop\u001b[38;5;241m.\u001b[39m_nest_asyncio_patched:\n\u001b[1;32m     57\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mget_event_loop()\u001b[38;5;241m.\u001b[39mrun_until_complete(asyncio\u001b[38;5;241m.\u001b[39mgather(future))[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfuture\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis event loop is already running\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "File \u001b[0;32m~/development/my_projects/.venv/lib/python3.12/site-packages/nest_asyncio.py:98\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEvent loop stopped before Future completed.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.12/asyncio/futures.py:203\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__log_traceback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 203\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception_tb)\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "File \u001b[0;32m/usr/lib/python3.12/asyncio/tasks.py:314\u001b[0m, in \u001b[0;36mTask.__step_run_and_handle_result\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    312\u001b[0m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[1;32m    313\u001b[0m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[0;32m--> 314\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mcoro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39mthrow(exc)\n",
      "File \u001b[0;32m<@beartype(superlinked.framework.dsl.query.query_mixin.QueryMixin.async_query) at 0x72cdb94122a0>:34\u001b[0m, in \u001b[0;36masync_query\u001b[0;34m(__beartype_object_1199700608, __beartype_get_violation, __beartype_conf, __beartype_args_name_keywordable, __beartype_object_1188762160, __beartype_check_meta, __beartype_func, *args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/development/my_projects/.venv/lib/python3.12/site-packages/superlinked/framework/dsl/query/query_mixin.py:78\u001b[0m, in \u001b[0;36mQueryMixin.async_query\u001b[0;34m(self, query_descriptor, **params)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21masync_query\u001b[39m(\u001b[38;5;28mself\u001b[39m, query_descriptor: QueryDescriptor, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m QueryResult:\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m query_vector_factory \u001b[38;5;241m:=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_query_vector_factory_by_index\u001b[38;5;241m.\u001b[39mget(query_descriptor\u001b[38;5;241m.\u001b[39mindex):\n\u001b[1;32m     77\u001b[0m         \u001b[38;5;66;03m# 'self' is an App instance; MyPy can't infer the inheriting class.\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m         query_result: QueryResult \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m QueryExecutor(\n\u001b[1;32m     79\u001b[0m             \u001b[38;5;28mself\u001b[39m, query_descriptor, query_vector_factory  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     80\u001b[0m         )\u001b[38;5;241m.\u001b[39mquery(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m     81\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_query_result_converter\u001b[38;5;241m.\u001b[39mconvert(query_result)\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m QueryException(\n\u001b[1;32m     84\u001b[0m         (\n\u001b[1;32m     85\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuery index \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery_descriptor\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not amongst the executor\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms indices: \u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     86\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_query_vector_factory_by_index\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     87\u001b[0m         )\n\u001b[1;32m     88\u001b[0m     )\n",
      "File \u001b[0;32m~/development/my_projects/.venv/lib/python3.12/site-packages/superlinked/framework/dsl/executor/query/query_executor.py:100\u001b[0m, in \u001b[0;36mQueryExecutor.query\u001b[0;34m(self, **params)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;124;03mExecute a query with keyword parameters.\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;124;03m    QueryException: If the query index is not amongst the executor's indices.\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__check_executor_has_index()\n\u001b[0;32m--> 100\u001b[0m query_descriptor: QueryDescriptor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m QueryParamValueSetter\u001b[38;5;241m.\u001b[39mset_values(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_query_descriptor, params)\n\u001b[1;32m    101\u001b[0m knn_search_params: KNNSearchParams \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_produce_knn_search_params(query_descriptor)\n\u001b[1;32m    102\u001b[0m entities \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_knn_search(\n\u001b[1;32m    103\u001b[0m     knn_search_params,\n\u001b[1;32m    104\u001b[0m     query_descriptor,\n\u001b[1;32m    105\u001b[0m     knn_search_params\u001b[38;5;241m.\u001b[39mshould_return_index_vector \u001b[38;5;129;01mor\u001b[39;00m query_descriptor\u001b[38;5;241m.\u001b[39mwith_metadata,\n\u001b[1;32m    106\u001b[0m )\n",
      "File \u001b[0;32m~/development/my_projects/.venv/lib/python3.12/site-packages/superlinked/framework/dsl/query/query_param_value_setter.py:37\u001b[0m, in \u001b[0;36mQueryParamValueSetter.set_values\u001b[0;34m(cls, query_descriptor, params)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mset_values\u001b[39m(\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28mcls\u001b[39m, query_descriptor: QueryDescriptor, params: Mapping[\u001b[38;5;28mstr\u001b[39m, ParamInputType \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m     35\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m QueryDescriptor:\n\u001b[1;32m     36\u001b[0m     query_descriptor_with_all_clauses \u001b[38;5;241m=\u001b[39m query_descriptor\u001b[38;5;241m.\u001b[39mappend_missing_mandatory_clauses()\n\u001b[0;32m---> 37\u001b[0m     \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_descriptor_with_all_clauses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     altered_query_descriptor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__alter_query_descriptor(query_descriptor_with_all_clauses, params, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     39\u001b[0m     nlq_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__calculate_nlq_params(altered_query_descriptor)\n",
      "File \u001b[0;32m~/development/my_projects/.venv/lib/python3.12/site-packages/superlinked/framework/dsl/query/query_param_value_setter.py:56\u001b[0m, in \u001b[0;36mQueryParamValueSetter.validate_params\u001b[0;34m(cls, query_descriptor, params_to_set)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m unknown_params:\n\u001b[1;32m     55\u001b[0m     unknown_params_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(unknown_params)\n\u001b[0;32m---> 56\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown query parameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00munknown_params_text\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown query parameters: natural_query."
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "def date_to_unix(date_str):\n",
    "    if date_str is None:\n",
    "        return None\n",
    "    return int(datetime.strptime(date_str, \"%d/%m/%Y\").timestamp())\n",
    "# Natural language query parameters\n",
    "params = {\n",
    "    \"natural_query\": \"Recent PDF files about fashion or sport\",\n",
    "    \"limit\": 5,\n",
    "}\n",
    "\n",
    "# Run the query with natural language interface\n",
    "result = app.query(query, **params)\n",
    "\n",
    "# Print the actual interpreted search parameters extracted by NLQ\n",
    "print(\"Search Parameters Parsed by NLQ:\")\n",
    "print(result.metadata.search_params)\n",
    "\n",
    "# Convert the results to a pandas DataFrame\n",
    "df = sl.PandasConverter.to_pandas(result)\n",
    "\n",
    "# Convert Unix timestamps to dd/mm/yyyy format in the DataFrame\n",
    "import pandas as pd\n",
    "df[\"Creation_Date\"] = pd.to_datetime(df[\"Creation_Date\"], unit=\"s\").dt.strftime(\"%d/%m/%Y\")\n",
    "df[\"Last_Modified_Date\"] = pd.to_datetime(df[\"Last_Modified_Date\"], unit=\"s\").dt.strftime(\"%d/%m/%Y\")\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>content_similarity</th>\n",
       "      <th>filename_similarity</th>\n",
       "      <th>size_score</th>\n",
       "      <th>creation_date_score</th>\n",
       "      <th>modified_date_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_56</td>\n",
       "      <td>0.150118</td>\n",
       "      <td>0.168721</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.307981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_68</td>\n",
       "      <td>0.140760</td>\n",
       "      <td>0.152928</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_62</td>\n",
       "      <td>0.120002</td>\n",
       "      <td>0.159565</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.279851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_89</td>\n",
       "      <td>0.095913</td>\n",
       "      <td>0.184917</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.275791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_92</td>\n",
       "      <td>0.122882</td>\n",
       "      <td>0.159565</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.261333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  content_similarity  filename_similarity  size_score  \\\n",
       "0  id_56            0.150118             0.168721         0.0   \n",
       "1  id_68            0.140760             0.152928         0.0   \n",
       "2  id_62            0.120002             0.159565         0.0   \n",
       "3  id_89            0.095913             0.184917         0.0   \n",
       "4  id_92            0.122882             0.159565         0.0   \n",
       "\n",
       "   creation_date_score  modified_date_score  \n",
       "0                  0.0             0.307981  \n",
       "1                  0.0             0.276024  \n",
       "2                  0.0             0.279851  \n",
       "3                  0.0             0.275791  \n",
       "4                  0.0             0.261333  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# These are the names of the semantic/numeric spaces in the same order as in your index.spaces list\n",
    "space_names = [\n",
    "    \"content_similarity\",\n",
    "    \"filename_similarity\",\n",
    "    \"size_score\",\n",
    "    \"creation_date_score\",\n",
    "    \"modified_date_score\"\n",
    "]\n",
    "\n",
    "rows = []\n",
    "\n",
    "for entry in result.entries:\n",
    "    partial_scores = dict(zip(space_names, entry.metadata.partial_scores))\n",
    "    row = {\"id\": entry.id, **partial_scores}\n",
    "    rows.append(row)\n",
    "    \n",
    "df = pd.DataFrame(rows)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "def date_to_unix(date_str):\n",
    "    if date_str is None:\n",
    "        return None\n",
    "    return int(datetime.strptime(date_str, \"%d/%m/%Y\").timestamp())\n",
    "\n",
    "# Define your parameters with human-readable date strings or None\n",
    "params = {\n",
    "    # Text similarity inputs\n",
    "    \"content_query\": \"cinema fashion\",\n",
    "    \"filename_query\": \"technical\",\n",
    "\n",
    "    # Weights for semantic spaces (matching what's in query.weights)\n",
    "    \"content_weight\": 0.0,\n",
    "    \"filename_weight\": 0.0,\n",
    "    \"size_weight\": 0.0,\n",
    "    \"creation_date_weight\": 1.0,\n",
    "    \"modified_date_weight\": 1.0,\n",
    "\n",
    "    # Weights for similarity matching\n",
    "    \"similar_content_weight\": 0.0,\n",
    "    \"similar_filename_weight\": 0.0,\n",
    "\n",
    "    # Size filters (in kilobytes)\n",
    "    #\"min_size_kb\": 1000,\n",
    "    #\"max_size_kb\": 10000,\n",
    "\n",
    "    # Date filters (input as \"dd/mm/yyyy\" strings or None)\n",
    "    \"min_creation_date\": date_to_unix(\"03/08/2021\"),\n",
    "    \"max_creation_date\": date_to_unix(\"31/12/2025\"),\n",
    "    \"min_modified_date\": date_to_unix(None),  # No lower bound\n",
    "    \"max_modified_date\": date_to_unix(\"30/06/2035\"),\n",
    "\n",
    "    # Categorical filters (must match query.py)\n",
    "    \"filetype_include_any\": ['pdf', 'docx'],\n",
    "    \"tags_include_any\": [\"cinema\", \"fashion\"],\n",
    "\n",
    "    # Result limit\n",
    "    \"limit\": 5,\n",
    "}\n",
    "\n",
    "# Run the query\n",
    "result = app.query(query, **params)\n",
    "\n",
    "# Inspect parameters used\n",
    "print(result.metadata.search_params)\n",
    "\n",
    "df = sl.PandasConverter.to_pandas(result)\n",
    "\n",
    "if df.empty:\n",
    "    print(\"No results found for the query.\")\n",
    "    # Optionally, return or display empty data\n",
    "    display(df)  # or simply do nothing / return\n",
    "else:\n",
    "    # Convert Unix timestamps (in milliseconds or seconds) to formatted dates\n",
    "    # Adjust unit='ms' or 's' as needed based on your data\n",
    "\n",
    "    # Example using 'ms' if timestamps are in milliseconds\n",
    "    df[\"Creation_Date\"] = pd.to_datetime(df[\"Creation_Date\"], unit=\"s\").dt.strftime(\"%d/%m/%Y\")\n",
    "    df[\"Last_Modified_Date\"] = pd.to_datetime(df[\"Last_Modified_Date\"], unit=\"s\").dt.strftime(\"%d/%m/%Y\")\n",
    "\n",
    "    display(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:35:40 superlinked.framework.query.query_dag_evaluator INFO   evaluated query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:35:41 httpx INFO   HTTP Request: POST https://bad13d43-afc8-44b5-8b37-2fa1eb4f0236.eu-west-1-0.aws.cloud.qdrant.io:6333/collections/file_monkesearch/points/query \"HTTP/1.1 200 OK\"\n",
      "16:35:42 superlinked.framework.dsl.executor.query.query_executor INFO   executed query\n",
      "{'contenttype_query': 'pdf document', 'similar_filter_TextSimilaritySpace_8831_FileDocument_ContentType_weight_param__': 1.0, 'kind_query': None, 'similar_filter_TextSimilaritySpace_ed01_FileDocument_Kind_weight_param__': 1.0, 'category_query': None, 'similar_filter_CategoricalSimilaritySpace_c7a6_FileDocument_ContentType_weight_param__': 1.0, 'name_query': 'CatastoAppartamento', 'similar_filter_TextSimilaritySpace_eba1_FileDocument_Name_weight_param__': 1.0, 'hard_filter_Size_be_greater_than_param__': 0.0, 'min_size_kb': 0.0, 'max_size_kb': 10000.0, 'min_creation_date': 1754172000, 'max_creation_date': 1767135600, 'min_modified_date': 0, 'max_modified_date': 2066767200, 'limit': 5, 'select_param__': ['ContentType', 'Kind', 'Name', 'Path', 'Size', 'CreationDate', 'ContentChangeDate'], 'radius_param__': None, 'contenttype_weight': 1.0, 'kind_weight': 1.0, 'category_weight': 1.0, 'name_weight': 0.0, 'size_weight': 1.0, 'creation_date_weight': 0.0, 'modified_date_weight': 0.0}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ContentType</th>\n",
       "      <th>Kind</th>\n",
       "      <th>Name</th>\n",
       "      <th>Path</th>\n",
       "      <th>Size</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>ContentChangeDate</th>\n",
       "      <th>id</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text/css</td>\n",
       "      <td>css</td>\n",
       "      <td>leaflet.awesome-markers.css</td>\n",
       "      <td>/home/biso/Downloads/Streamlit_files/leaflet.a...</td>\n",
       "      <td>2225.0</td>\n",
       "      <td>23/08/2025</td>\n",
       "      <td>23/08/2025</td>\n",
       "      <td>id_200</td>\n",
       "      <td>0.614059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>dataset.jsonl</td>\n",
       "      <td>/home/biso/Downloads/dataset.jsonl</td>\n",
       "      <td>549.0</td>\n",
       "      <td>07/08/2025</td>\n",
       "      <td>07/08/2025</td>\n",
       "      <td>id_109</td>\n",
       "      <td>0.611418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>text/javascript</td>\n",
       "      <td>javascript</td>\n",
       "      <td>leaflet.awesome-markers.js</td>\n",
       "      <td>/home/biso/Downloads/Streamlit_files/leaflet.a...</td>\n",
       "      <td>3789.0</td>\n",
       "      <td>23/08/2025</td>\n",
       "      <td>23/08/2025</td>\n",
       "      <td>id_184</td>\n",
       "      <td>0.571546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>application/pgp-keys</td>\n",
       "      <td>pgp-keys</td>\n",
       "      <td>ssh-key-2025-08-30.key</td>\n",
       "      <td>/home/biso/Downloads/ssh-key-2025-08-30.key</td>\n",
       "      <td>1675.0</td>\n",
       "      <td>30/08/2025</td>\n",
       "      <td>30/08/2025</td>\n",
       "      <td>id_71</td>\n",
       "      <td>0.567931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>application/vnd.exstream-package</td>\n",
       "      <td>vnd.exstream-package</td>\n",
       "      <td>ssh-key-2025-08-30.key.pub</td>\n",
       "      <td>/home/biso/Downloads/ssh-key-2025-08-30.key.pub</td>\n",
       "      <td>399.0</td>\n",
       "      <td>30/08/2025</td>\n",
       "      <td>30/08/2025</td>\n",
       "      <td>id_36</td>\n",
       "      <td>0.555531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        ContentType                  Kind  \\\n",
       "0                          text/css                   css   \n",
       "1                           unknown               unknown   \n",
       "2                   text/javascript            javascript   \n",
       "3              application/pgp-keys              pgp-keys   \n",
       "4  application/vnd.exstream-package  vnd.exstream-package   \n",
       "\n",
       "                          Name  \\\n",
       "0  leaflet.awesome-markers.css   \n",
       "1                dataset.jsonl   \n",
       "2   leaflet.awesome-markers.js   \n",
       "3       ssh-key-2025-08-30.key   \n",
       "4   ssh-key-2025-08-30.key.pub   \n",
       "\n",
       "                                                Path    Size CreationDate  \\\n",
       "0  /home/biso/Downloads/Streamlit_files/leaflet.a...  2225.0   23/08/2025   \n",
       "1                 /home/biso/Downloads/dataset.jsonl   549.0   07/08/2025   \n",
       "2  /home/biso/Downloads/Streamlit_files/leaflet.a...  3789.0   23/08/2025   \n",
       "3        /home/biso/Downloads/ssh-key-2025-08-30.key  1675.0   30/08/2025   \n",
       "4    /home/biso/Downloads/ssh-key-2025-08-30.key.pub   399.0   30/08/2025   \n",
       "\n",
       "  ContentChangeDate      id  similarity_score  \n",
       "0        23/08/2025  id_200          0.614059  \n",
       "1        07/08/2025  id_109          0.611418  \n",
       "2        23/08/2025  id_184          0.571546  \n",
       "3        30/08/2025   id_71          0.567931  \n",
       "4        30/08/2025   id_36          0.555531  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def date_to_unix(date_str):\n",
    "    if date_str is None:\n",
    "        # Use zero for no lower bound, not None (filters expect int)\n",
    "        return 0\n",
    "    return int(datetime.strptime(date_str, \"%d/%m/%Y\").timestamp())\n",
    "\n",
    "\n",
    "# Define your parameters matching the query.py\n",
    "params = {\n",
    "    # Semantic similarity text query per space\n",
    "    \"contenttype_query\": \"pdf document\",\n",
    "    \"name_query\": \"CatastoAppartamento\",\n",
    "\n",
    "    # Weights for semantic spaces as defined in query weights\n",
    "    \"contenttype_weight\": 1.0,\n",
    "    \"kind_weight\": 1.0,\n",
    "    \"category_weight\": 1.0,\n",
    "    \"name_weight\": 0.0,\n",
    "    \"size_weight\": 1.0,  # Filter only, no similarity weight on size\n",
    "    \"creation_date_weight\": 0.0,\n",
    "    \"modified_date_weight\": 0.0,\n",
    "\n",
    "    # Size filters (bytes)\n",
    "    \"min_size_kb\": 0,\n",
    "    \"max_size_kb\": 10000,\n",
    "\n",
    "    # Date filters (Unix timestamps in seconds)\n",
    "    \"min_creation_date\": date_to_unix(\"03/08/2025\"),\n",
    "    \"max_creation_date\": date_to_unix(\"31/12/2025\"),\n",
    "    \"min_modified_date\": date_to_unix(None),  # 0 means no lower bound\n",
    "    \"max_modified_date\": date_to_unix(\"30/06/2035\"),\n",
    "\n",
    "    # If you have categorical filters (make sure implemented in query)\n",
    "    # \"filetype_include_any\": ['pdf', 'docx'],\n",
    "    # \"tags_include_any\": [\"cinema\", \"fashion\"],\n",
    "\n",
    "    # Limit of results\n",
    "    \"limit\": 5,\n",
    "}\n",
    "\n",
    "\n",
    "# Run the query\n",
    "result = app.query(query, **params)\n",
    "\n",
    "\n",
    "# Inspect parameters used\n",
    "print(result.metadata.search_params)\n",
    "\n",
    "\n",
    "df = sl.PandasConverter.to_pandas(result)\n",
    "\n",
    "if df.empty:\n",
    "    print(\"No results found for the query.\")\n",
    "    display(df)\n",
    "else:\n",
    "    # Convert Unix timestamps (in seconds) to formatted date strings\n",
    "    df[\"CreationDate\"] = pd.to_datetime(df[\"CreationDate\"], unit=\"s\").dt.strftime(\"%d/%m/%Y\")\n",
    "    df[\"ContentChangeDate\"] = pd.to_datetime(df[\"ContentChangeDate\"], unit=\"s\").dt.strftime(\"%d/%m/%Y\")\n",
    "\n",
    "    display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>contenttype_score</th>\n",
       "      <th>kind_space_score</th>\n",
       "      <th>category_score</th>\n",
       "      <th>name_score</th>\n",
       "      <th>size_score</th>\n",
       "      <th>creation_date_score</th>\n",
       "      <th>modified_date_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_200</td>\n",
       "      <td>0.114105</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.499954</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_109</td>\n",
       "      <td>0.111464</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.499954</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_184</td>\n",
       "      <td>0.071592</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.499954</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_71</td>\n",
       "      <td>0.067977</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.499954</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_36</td>\n",
       "      <td>0.055577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.499954</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  contenttype_score  kind_space_score  category_score  name_score  \\\n",
       "0  id_200           0.114105               0.0             0.0         0.0   \n",
       "1  id_109           0.111464               0.0             0.0         0.0   \n",
       "2  id_184           0.071592               0.0             0.0         0.0   \n",
       "3   id_71           0.067977               0.0             0.0         0.0   \n",
       "4   id_36           0.055577               0.0             0.0         0.0   \n",
       "\n",
       "   size_score  creation_date_score  modified_date_score  \n",
       "0    0.499954                  0.0                  0.0  \n",
       "1    0.499954                  0.0                  0.0  \n",
       "2    0.499954                  0.0                  0.0  \n",
       "3    0.499954                  0.0                  0.0  \n",
       "4    0.499954                  0.0                  0.0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# These are the names of the semantic/numeric spaces in the same order as in your index.spaces list\n",
    "space_names = [\n",
    "    \"contenttype_score\",\n",
    "    \"kind_space_score\",\n",
    "    \"category_score\",\n",
    "    \"name_score\",\n",
    "    \"size_score\",\n",
    "    \"creation_date_score\",\n",
    "    \"modified_date_score\",\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "rows = []\n",
    "\n",
    "for entry in result.entries:\n",
    "    partial_scores = dict(zip(space_names, entry.metadata.partial_scores))\n",
    "    row = {\"id\": entry.id, **partial_scores}\n",
    "    rows.append(row)\n",
    "    \n",
    "df = pd.DataFrame(rows)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query with simple_query without LLM imported from monkeSearch leann-plus-temporal-search.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98c14b3321604d74b72478640f0f5994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adf55ea27b8e4ddfbb7519bcc1ec338f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3612ab69a41b4f0baf9d606be7acc32d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:24:29 superlinked.framework.query.query_dag_evaluator INFO   evaluated query\n",
      "17:24:31 httpx INFO   HTTP Request: POST https://bad13d43-afc8-44b5-8b37-2fa1eb4f0236.eu-west-1-0.aws.cloud.qdrant.io:6333/collections/file_monkesearch/points/query \"HTTP/1.1 200 OK\"\n",
      "17:24:31 superlinked.framework.dsl.executor.query.query_executor INFO   executed query\n",
      "\n",
      "Search results for: 'image from approximately 1 month ago'\n",
      "Time filter: 1 month(s) (fuzzy)\n",
      "Date range: 2025-08-30 to 2025-09-11\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ContentType</th>\n",
       "      <th>Kind</th>\n",
       "      <th>Name</th>\n",
       "      <th>Path</th>\n",
       "      <th>Size</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>ContentChangeDate</th>\n",
       "      <th>id</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>application/json</td>\n",
       "      <td>json</td>\n",
       "      <td>veneto_poi.json</td>\n",
       "      <td>/home/biso/Downloads/veneto_poi.json</td>\n",
       "      <td>1393.0</td>\n",
       "      <td>02/09/2025</td>\n",
       "      <td>02/09/2025</td>\n",
       "      <td>id_121</td>\n",
       "      <td>0.561631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>application/json</td>\n",
       "      <td>json</td>\n",
       "      <td>veneto_locations (1).json</td>\n",
       "      <td>/home/biso/Downloads/veneto_locations (1).json</td>\n",
       "      <td>1393.0</td>\n",
       "      <td>02/09/2025</td>\n",
       "      <td>02/09/2025</td>\n",
       "      <td>id_32</td>\n",
       "      <td>0.561631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>application/json</td>\n",
       "      <td>json</td>\n",
       "      <td>veneto_locations.json</td>\n",
       "      <td>/home/biso/Downloads/veneto_locations.json</td>\n",
       "      <td>1601.0</td>\n",
       "      <td>02/09/2025</td>\n",
       "      <td>02/09/2025</td>\n",
       "      <td>id_82</td>\n",
       "      <td>0.561631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ContentType  Kind                       Name  \\\n",
       "0  application/json  json            veneto_poi.json   \n",
       "1  application/json  json  veneto_locations (1).json   \n",
       "2  application/json  json      veneto_locations.json   \n",
       "\n",
       "                                             Path    Size CreationDate  \\\n",
       "0            /home/biso/Downloads/veneto_poi.json  1393.0   02/09/2025   \n",
       "1  /home/biso/Downloads/veneto_locations (1).json  1393.0   02/09/2025   \n",
       "2      /home/biso/Downloads/veneto_locations.json  1601.0   02/09/2025   \n",
       "\n",
       "  ContentChangeDate      id  similarity_score  \n",
       "0        02/09/2025  id_121          0.561631  \n",
       "1        02/09/2025   id_32          0.561631  \n",
       "2        02/09/2025   id_82          0.561631  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "from superlinked import framework as sl\n",
    "\n",
    "# --- TimeParser class reused ---\n",
    "class TimeParser:\n",
    "    def __init__(self):\n",
    "        self.pattern = r'(?:(around|about|roughly|approximately)\\s+)?(\\d+)\\s+(hour|day|week|month|year)s?(?:\\s+ago)?'\n",
    "        self.regex = re.compile(self.pattern, re.IGNORECASE)\n",
    "        self.stop_words = {\n",
    "            'in', 'at', 'of', 'by', 'as', 'me',\n",
    "            'the', 'a', 'an', 'and', 'any',\n",
    "            'find', 'search', 'list',\n",
    "            'ago', 'back',\n",
    "            'past', 'earlier',\n",
    "        }\n",
    "\n",
    "    def clean_text(self, text):\n",
    "        words = text.split()\n",
    "        cleaned = ' '.join(word for word in words if word.lower() not in self.stop_words)\n",
    "        return cleaned\n",
    "\n",
    "    def parse(self, text):\n",
    "        cleaned_text = self.clean_text(text)\n",
    "        matches = []\n",
    "        for match in self.regex.finditer(cleaned_text):\n",
    "            fuzzy = match.group(1)\n",
    "            number = int(match.group(2))\n",
    "            unit = match.group(3).lower()\n",
    "            matches.append({\n",
    "                'full_match': match.group(0),\n",
    "                'fuzzy': bool(fuzzy),\n",
    "                'number': number,\n",
    "                'unit': unit,\n",
    "                'range': self.calculate_range(number, unit, bool(fuzzy))\n",
    "            })\n",
    "        return matches\n",
    "\n",
    "    def calculate_range(self, number, unit, is_fuzzy):\n",
    "        units = {\n",
    "            'hour': timedelta(hours=number),\n",
    "            'day': timedelta(days=number),\n",
    "            'week': timedelta(weeks=number),\n",
    "            'month': timedelta(days=number * 30),\n",
    "            'year': timedelta(days=number * 365)\n",
    "        }\n",
    "        delta = units[unit]\n",
    "        now = datetime.now()\n",
    "        target = now - delta\n",
    "        if is_fuzzy:\n",
    "            buffer = delta * 0.2\n",
    "            start = (target - buffer).isoformat()\n",
    "            end = (target + buffer).isoformat()\n",
    "        else:\n",
    "            start = target.isoformat()\n",
    "            end = now.isoformat()\n",
    "        return (start, end)\n",
    "\n",
    "\n",
    "def date_to_unix(date_str):\n",
    "    if date_str is None:\n",
    "        return 0\n",
    "    return int(datetime.strptime(date_str, \"%d/%m/%Y\").timestamp())\n",
    "\n",
    "\n",
    "\n",
    "def search_files_superlinked(app, query, raw_query, top_k=15):\n",
    "    parser = TimeParser()\n",
    "    time_matches = parser.parse(raw_query)\n",
    "\n",
    "    clean_query = raw_query\n",
    "    if time_matches:\n",
    "        for match in time_matches:\n",
    "            clean_query = clean_query.replace(match['full_match'], '').strip()\n",
    "\n",
    "    if len(clean_query) < 4:\n",
    "        print(\"Error: add more input for accurate results.\")\n",
    "        return\n",
    "\n",
    "    params = {\n",
    "        \"contenttype_query\": clean_query,\n",
    "        \"kind_query\": clean_query,\n",
    "        \"category_query\": clean_query,\n",
    "        \"name_query\": clean_query,\n",
    "\n",
    "        \"contenttype_weight\": 1.0,\n",
    "        \"kind_weight\": 1.0,\n",
    "        \"category_weight\": 1.0,\n",
    "        \"name_weight\": 0.0,\n",
    "        \"size_weight\": 1.0,\n",
    "        \"creation_date_weight\": 0.0,\n",
    "        \"modified_date_weight\": 0.0,\n",
    "\n",
    "        \"min_size_kb\": 0,\n",
    "        \"max_size_kb\": 10000,\n",
    "\n",
    "        \"min_creation_date\": 0,\n",
    "        \"max_creation_date\": 4102444800,\n",
    "        \"min_modified_date\": 0,\n",
    "        \"max_modified_date\": 4102444800,\n",
    "\n",
    "        \"limit\": top_k,\n",
    "    }\n",
    "\n",
    "    if time_matches:\n",
    "        start_iso, end_iso = time_matches[0]['range']\n",
    "        params[\"min_creation_date\"] = int(datetime.fromisoformat(start_iso).timestamp())\n",
    "        params[\"max_creation_date\"] = int(datetime.fromisoformat(end_iso).timestamp())\n",
    "        params[\"min_modified_date\"] = int(datetime.fromisoformat(start_iso).timestamp())\n",
    "        params[\"max_modified_date\"] = int(datetime.fromisoformat(end_iso).timestamp())\n",
    "\n",
    "    result = app.query(query, **params)\n",
    "\n",
    "    print(f\"\\nSearch results for: '{raw_query}'\")\n",
    "    if time_matches:\n",
    "        print(f\"Time filter: {time_matches[0]['number']} {time_matches[0]['unit']}(s) {'(fuzzy)' if time_matches[0]['fuzzy'] else ''}\")\n",
    "        print(f\"Date range: {start_iso[:10]} to {end_iso[:10]}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    df = sl.PandasConverter.to_pandas(result)\n",
    "    if df.empty:\n",
    "        print(\"No results found.\")\n",
    "        return\n",
    "\n",
    "    df[\"CreationDate\"] = pd.to_datetime(df[\"CreationDate\"], unit=\"s\").dt.strftime(\"%d/%m/%Y\")\n",
    "    df[\"ContentChangeDate\"] = pd.to_datetime(df[\"ContentChangeDate\"], unit=\"s\").dt.strftime(\"%d/%m/%Y\")\n",
    "\n",
    "    display(df)\n",
    "\n",
    "\n",
    "# Example of manual execution in notebook:\n",
    "\n",
    "# Be sure to initialize your Superlinked app and query beforehand.\n",
    "\n",
    "raw_query = \"image from approximately 1 month ago\"\n",
    "top_k = 10\n",
    "search_files_superlinked(app, query, raw_query, top_k)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
