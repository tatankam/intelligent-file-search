{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this notebook in the same virtual environment with superlinked server\n",
    "to ensure the same version of `superlinked` framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze | grep superlinked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project_dir is already in sys.path\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Determine current working directory\n",
    "cwd = Path.cwd()\n",
    "\n",
    "# Adapt logic for your specific project structure\n",
    "if cwd.name == \"intelligent-file-search\":\n",
    "    project_dir = cwd\n",
    "elif cwd.name == \"notebooks\":\n",
    "    project_dir = cwd.parent\n",
    "else:\n",
    "    # fallback (e.g., if inside a subfolder deeper in notebooks or dataset)\n",
    "    project_dir = cwd\n",
    "    while project_dir.name != \"intelligent-file-search\" and project_dir != project_dir.parent:\n",
    "        project_dir = project_dir.parent\n",
    "\n",
    "superlinked_app_dir = project_dir / \"superlinked_app\"\n",
    "assert superlinked_app_dir.exists(), (\n",
    "    f\"{superlinked_app_dir} does not exist\\n\"\n",
    "    \"Are you sure you are in or below the intelligent-file-search directory?\"\n",
    ")\n",
    "\n",
    "if str(project_dir) not in sys.path:\n",
    "    sys.path.append(str(project_dir))\n",
    "    print(\"project_dir is added to sys.path\")\n",
    "else:\n",
    "    print(\"project_dir is already in sys.path\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is to use the collection_name=filesearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"APP_ID\"] = \"filesearch\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from superlinked import framework as sl\n",
    "\n",
    "from superlinked_app.index import index, file_schema\n",
    "from superlinked_app.query import query\n",
    "from superlinked_app.api import vector_database\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:44:46 httpx INFO   HTTP Request: GET https://bad13d43-afc8-44b5-8b37-2fa1eb4f0236.eu-west-1-0.aws.cloud.qdrant.io:6333/collections/filesearch/exists \"HTTP/1.1 200 OK\"\n",
      "17:44:46 httpx INFO   HTTP Request: GET https://bad13d43-afc8-44b5-8b37-2fa1eb4f0236.eu-west-1-0.aws.cloud.qdrant.io:6333/collections/filesearch \"HTTP/1.1 200 OK\"\n",
      "17:44:46 httpx INFO   HTTP Request: PUT https://bad13d43-afc8-44b5-8b37-2fa1eb4f0236.eu-west-1-0.aws.cloud.qdrant.io:6333/collections/filesearch/index?wait=true \"HTTP/1.1 200 OK\"\n",
      "17:44:46 httpx INFO   HTTP Request: PUT https://bad13d43-afc8-44b5-8b37-2fa1eb4f0236.eu-west-1-0.aws.cloud.qdrant.io:6333/collections/filesearch/index?wait=true \"HTTP/1.1 200 OK\"\n",
      "17:44:46 httpx INFO   HTTP Request: PUT https://bad13d43-afc8-44b5-8b37-2fa1eb4f0236.eu-west-1-0.aws.cloud.qdrant.io:6333/collections/filesearch/index?wait=true \"HTTP/1.1 200 OK\"\n",
      "17:44:46 httpx INFO   HTTP Request: PUT https://bad13d43-afc8-44b5-8b37-2fa1eb4f0236.eu-west-1-0.aws.cloud.qdrant.io:6333/collections/filesearch/index?wait=true \"HTTP/1.1 200 OK\"\n",
      "17:44:46 httpx INFO   HTTP Request: PUT https://bad13d43-afc8-44b5-8b37-2fa1eb4f0236.eu-west-1-0.aws.cloud.qdrant.io:6333/collections/filesearch/index?wait=true \"HTTP/1.1 200 OK\"\n",
      "17:44:46 httpx INFO   HTTP Request: PUT https://bad13d43-afc8-44b5-8b37-2fa1eb4f0236.eu-west-1-0.aws.cloud.qdrant.io:6333/collections/filesearch/index?wait=true \"HTTP/1.1 200 OK\"\n",
      "17:44:46 httpx INFO   HTTP Request: PUT https://bad13d43-afc8-44b5-8b37-2fa1eb4f0236.eu-west-1-0.aws.cloud.qdrant.io:6333/collections/filesearch/index?wait=true \"HTTP/1.1 200 OK\"\n",
      "17:44:46 httpx INFO   HTTP Request: PUT https://bad13d43-afc8-44b5-8b37-2fa1eb4f0236.eu-west-1-0.aws.cloud.qdrant.io:6333/collections/filesearch/index?wait=true \"HTTP/1.1 200 OK\"\n",
      "17:44:47 httpx INFO   HTTP Request: PUT https://bad13d43-afc8-44b5-8b37-2fa1eb4f0236.eu-west-1-0.aws.cloud.qdrant.io:6333/collections/filesearch/index?wait=true \"HTTP/1.1 200 OK\"\n",
      "17:44:47 superlinked.framework.query.query_dag_evaluator INFO   initialized query dag\n",
      "17:44:47 superlinked.framework.online.online_dag_evaluator INFO   initialized entity dag\n",
      "17:44:47 superlinked.framework.dsl.executor.interactive.interactive_executor INFO   started interactive app\n"
     ]
    }
   ],
   "source": [
    "source = sl.InteractiveSource(file_schema)\n",
    "executor = sl.InteractiveExecutor(\n",
    "    sources=[source],\n",
    "    indices=[index],\n",
    "    vector_database=vector_database,\n",
    ")\n",
    "app = executor.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:48:10 httpx INFO   HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "17:48:13 superlinked.framework.query.query_dag_evaluator INFO   evaluated query\n",
      "17:48:13 httpx INFO   HTTP Request: POST https://bad13d43-afc8-44b5-8b37-2fa1eb4f0236.eu-west-1-0.aws.cloud.qdrant.io:6333/collections/filesearch/points/query \"HTTP/1.1 200 OK\"\n",
      "17:48:14 superlinked.framework.dsl.executor.query.query_executor INFO   executed query\n",
      "Search Parameters Parsed by NLQ:\n",
      "{'content_query': 'fashion or sport', 'similar_content_weight': 1.0, 'filename_query': 'pdf', 'similar_filename_weight': 1.0, 'limit': 5, 'select_param__': ['Content', 'File_Type', 'Tags', 'Filename', 'Path', 'Size_kB', 'Creation_Date', 'Last_Modified_Date'], 'min_size_kb': None, 'max_size_kb': None, 'min_creation_date': None, 'max_creation_date': None, 'min_modified_date': None, 'max_modified_date': 1609459200, 'filetype_include_all': None, 'filetype_include_any': ['pdf'], 'filetype_exclude': None, 'tags_include_all': None, 'tags_include_any': ['fashion', 'sport'], 'tags_exclude': None, 'natural_query': 'Recent PDF files about fashion or sport', 'system_prompt_param__': \"Extract search parameters from the user's natural language query about files.\\nGuidelines:\\n- Identify semantic queries about content or file name.\\n- Use file type and tags as categorical filters.\\n- Size in kilobytes may be specified as small/large or by value.\\n- Creation and modification dates may indicate recency.\\n- If no preference is mentioned for a field, use None.\\n- Examples:\\n  1. User query: 'Recent PDF files about fashion or sport' -> file_type: 'pdf', tags: ['fashion', 'sport'], prioritize modified_date.\\n  2. User query: 'Large Word documents about tennis' -> file_type: 'docx', content: 'tennis', size: high.\\n  3. User query: 'Old reports about cinema and cars' -> tags: ['cinema', 'cars'], prioritize old creation_date.\\n  4. User query: 'Documents mentioning basketball' -> content: 'basketball'\\n\", 'radius_param__': None, 'content_weight': 1.0, 'filename_weight': 1.0, 'size_weight': 0.0, 'creation_date_weight': 0.0, 'modified_date_weight': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>File_Type</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Path</th>\n",
       "      <th>Size_kB</th>\n",
       "      <th>Creation_Date</th>\n",
       "      <th>Last_Modified_Date</th>\n",
       "      <th>id</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model designer trend dress.</td>\n",
       "      <td>[pdf]</td>\n",
       "      <td>[fashion]</td>\n",
       "      <td>trend.pdf</td>\n",
       "      <td>/focus/impact/sound/trend.pdf</td>\n",
       "      <td>8776.0</td>\n",
       "      <td>20/12/2001</td>\n",
       "      <td>24/01/2014</td>\n",
       "      <td>id_96</td>\n",
       "      <td>0.534661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Basketball athlete tennis football championshi...</td>\n",
       "      <td>[pdf]</td>\n",
       "      <td>[sport, fashion, cinema]</td>\n",
       "      <td>basketba.pdf</td>\n",
       "      <td>/argue/basketba.pdf</td>\n",
       "      <td>6608.0</td>\n",
       "      <td>09/11/2012</td>\n",
       "      <td>17/10/2014</td>\n",
       "      <td>id_58</td>\n",
       "      <td>0.525690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Award movie scene director scene movie. Footba...</td>\n",
       "      <td>[pdf]</td>\n",
       "      <td>[cinema, sport, cars]</td>\n",
       "      <td>award.pdf</td>\n",
       "      <td>/financial/under/three/award.pdf</td>\n",
       "      <td>8383.0</td>\n",
       "      <td>24/11/2001</td>\n",
       "      <td>16/12/2011</td>\n",
       "      <td>id_20</td>\n",
       "      <td>0.475729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Athlete football athlete football athlete bask...</td>\n",
       "      <td>[pdf]</td>\n",
       "      <td>[sport]</td>\n",
       "      <td>athlete.pdf</td>\n",
       "      <td>/still/everything/economic/athlete.pdf</td>\n",
       "      <td>1114.0</td>\n",
       "      <td>28/05/2010</td>\n",
       "      <td>16/02/2014</td>\n",
       "      <td>id_24</td>\n",
       "      <td>0.428723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content File_Type  \\\n",
       "0                        Model designer trend dress.     [pdf]   \n",
       "1  Basketball athlete tennis football championshi...     [pdf]   \n",
       "2  Award movie scene director scene movie. Footba...     [pdf]   \n",
       "3  Athlete football athlete football athlete bask...     [pdf]   \n",
       "\n",
       "                       Tags      Filename  \\\n",
       "0                 [fashion]     trend.pdf   \n",
       "1  [sport, fashion, cinema]  basketba.pdf   \n",
       "2     [cinema, sport, cars]     award.pdf   \n",
       "3                   [sport]   athlete.pdf   \n",
       "\n",
       "                                     Path  Size_kB Creation_Date  \\\n",
       "0           /focus/impact/sound/trend.pdf   8776.0    20/12/2001   \n",
       "1                     /argue/basketba.pdf   6608.0    09/11/2012   \n",
       "2        /financial/under/three/award.pdf   8383.0    24/11/2001   \n",
       "3  /still/everything/economic/athlete.pdf   1114.0    28/05/2010   \n",
       "\n",
       "  Last_Modified_Date     id  similarity_score  \n",
       "0         24/01/2014  id_96          0.534661  \n",
       "1         17/10/2014  id_58          0.525690  \n",
       "2         16/12/2011  id_20          0.475729  \n",
       "3         16/02/2014  id_24          0.428723  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "def date_to_unix(date_str):\n",
    "    if date_str is None:\n",
    "        return None\n",
    "    return int(datetime.strptime(date_str, \"%d/%m/%Y\").timestamp())\n",
    "# Natural language query parameters\n",
    "params = {\n",
    "    \"natural_query\": \"Recent PDF files about fashion or sport\",\n",
    "    \"limit\": 5,\n",
    "}\n",
    "\n",
    "# Run the query with natural language interface\n",
    "result = app.query(query, **params)\n",
    "\n",
    "# Print the actual interpreted search parameters extracted by NLQ\n",
    "print(\"Search Parameters Parsed by NLQ:\")\n",
    "print(result.metadata.search_params)\n",
    "\n",
    "# Convert the results to a pandas DataFrame\n",
    "df = sl.PandasConverter.to_pandas(result)\n",
    "\n",
    "# Convert Unix timestamps to dd/mm/yyyy format in the DataFrame\n",
    "import pandas as pd\n",
    "df[\"Creation_Date\"] = pd.to_datetime(df[\"Creation_Date\"], unit=\"s\").dt.strftime(\"%d/%m/%Y\")\n",
    "df[\"Last_Modified_Date\"] = pd.to_datetime(df[\"Last_Modified_Date\"], unit=\"s\").dt.strftime(\"%d/%m/%Y\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# These are the names of the semantic/numeric spaces in the same order as in your index.spaces list\n",
    "space_names = [\n",
    "    \"content_similarity\",\n",
    "    \"filename_similarity\",\n",
    "    \"size_score\",\n",
    "    \"creation_date_score\",\n",
    "    \"modified_date_score\"\n",
    "]\n",
    "\n",
    "rows = []\n",
    "\n",
    "for entry in result.entries:\n",
    "    partial_scores = dict(zip(space_names, entry.metadata.partial_scores))\n",
    "    row = {\"id\": entry.id, **partial_scores}\n",
    "    rows.append(row)\n",
    "    \n",
    "df = pd.DataFrame(rows)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "def date_to_unix(date_str):\n",
    "    if date_str is None:\n",
    "        return None\n",
    "    return int(datetime.strptime(date_str, \"%d/%m/%Y\").timestamp())\n",
    "\n",
    "# Define your parameters with human-readable date strings or None\n",
    "params = {\n",
    "    # Text similarity inputs\n",
    "    \"content_query\": \"cinema fashion\",\n",
    "    \"filename_query\": \"technical\",\n",
    "\n",
    "    # Weights for semantic spaces (matching what's in query.weights)\n",
    "    \"content_weight\": 1.0,\n",
    "    \"filename_weight\": 0.8,\n",
    "    \"size_weight\": 0.5,\n",
    "    \"creation_date_weight\": 0.6,\n",
    "    \"modified_date_weight\": 1.0,\n",
    "\n",
    "    # Weights for similarity matching\n",
    "    \"similar_content_weight\": 1.0,\n",
    "    \"similar_filename_weight\": 1.0,\n",
    "\n",
    "    # Size filters (in kilobytes)\n",
    "    \"min_size_kb\": 1000,\n",
    "    \"max_size_kb\": 10000,\n",
    "\n",
    "    # Date filters (input as \"dd/mm/yyyy\" strings or None)\n",
    "    \"min_creation_date\": date_to_unix(\"01/01/2020\"),\n",
    "    \"max_creation_date\": date_to_unix(\"31/12/2024\"),\n",
    "    \"min_modified_date\": date_to_unix(None),  # No lower bound\n",
    "    \"max_modified_date\": date_to_unix(\"30/06/2025\"),\n",
    "\n",
    "    # Categorical filters (must match query.py)\n",
    "    \"filetype_include_any\": [\"pdf\"],\n",
    "    \"tags_include_any\": [\"cinema\", \"fashion\"],\n",
    "\n",
    "    # Result limit\n",
    "    \"limit\": 5,\n",
    "}\n",
    "\n",
    "# Run the query\n",
    "result = app.query(query, **params)\n",
    "\n",
    "# Inspect parameters used\n",
    "print(result.metadata.search_params)\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "df = sl.PandasConverter.to_pandas(result)\n",
    "\n",
    "# Convert Unix timestamps in the DataFrame to dd/mm/yyyy strings for display\n",
    "df[\"Creation_Date\"] = pd.to_datetime(df[\"Creation_Date\"], unit=\"s\").dt.strftime(\"%d/%m/%Y\")\n",
    "df[\"Last_Modified_Date\"] = pd.to_datetime(df[\"Last_Modified_Date\"], unit=\"s\").dt.strftime(\"%d/%m/%Y\")\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# These are the names of the semantic/numeric spaces in the same order as in your index.spaces list\n",
    "space_names = [\n",
    "    \"content_similarity\",\n",
    "    \"filename_similarity\",\n",
    "    \"size_score\",\n",
    "    \"creation_date_score\",\n",
    "    \"modified_date_score\"\n",
    "]\n",
    "\n",
    "rows = []\n",
    "\n",
    "for entry in result.entries:\n",
    "    partial_scores = dict(zip(space_names, entry.metadata.partial_scores))\n",
    "    row = {\"id\": entry.id, **partial_scores}\n",
    "    rows.append(row)\n",
    "    \n",
    "df = pd.DataFrame(rows)\n",
    "df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
